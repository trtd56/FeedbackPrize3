{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac06e77-7e5a-401b-8c38-7002fcb8a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289abe66-081e-43f4-bdb4-a9c5b41906ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p .kaggle\n",
    "!cp \"./kaggle.json\" .kaggle/\n",
    "!chmod 600 .kaggle/kaggle.json\n",
    "!cp -r .kaggle /root\n",
    "\n",
    "!kaggle -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886bafc-ebb1-4ab5-a790-6b56c2214807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# competition data\n",
    "#!kaggle competitions download -c feedback-prize-english-language-learning\n",
    "#!unzip feedback-prize-english-language-learning.zip\n",
    "#!rm -rf feedback-prize-english-language-learning.zip\n",
    "#!mkdir -p competition_data\n",
    "#!mv sample_submission.csv test.csv train.csv competition_data/\n",
    "!echo \"### competition data ###\"\n",
    "!ls /content/competition_data/\n",
    "!echo\n",
    "\n",
    "# pseudo labels\n",
    "#!mkdir -p fb3-distillation-data-final\n",
    "#!kaggle kernels output takamichitoda/fb3-make-avg-distillation-pseudo -p ./fb3-distillation-data-final\n",
    "!echo \"### pseudo data ###\"\n",
    "!ls ./fb3-distillation-data-final\n",
    "!echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c21f6-b52a-42d9-8531-d2e916536448",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install iterative-stratification==0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0624eaa2-2cbd-452e-8b1c-289dee833c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "cuda\n",
      "transformers.__version__: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "is_gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_gpu else 'cpu')\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=is_gpu)\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(device)\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20c1dc3-1710-4b70-915c-051a9c94a912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /home/jupyter/output/distribution/dataset-metadata.json\n",
      "{'title': 'FB3 distribution last', 'id': 'takamichitoda/FB3-distribution-last', 'licenses': [{'name': 'CC0-1.0'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: home/jupyter/output/distribution//tokenizer/ (stored 0%)\n",
      "  adding: home/jupyter/output/distribution//tokenizer/special_tokens_map.json (deflated 54%)\n",
      "  adding: home/jupyter/output/distribution//tokenizer/added_tokens.json (stored 0%)\n",
      "  adding: home/jupyter/output/distribution//tokenizer/tokenizer.json (deflated 77%)\n",
      "  adding: home/jupyter/output/distribution//tokenizer/tokenizer_config.json (deflated 45%)\n",
      "  adding: home/jupyter/output/distribution//tokenizer/spm.model (deflated 50%)\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    EXP_NUM = 15\n",
    "    MEMO = \"final\"\n",
    "\n",
    "    INPUT = \"/home/jupyter/competition_data\"\n",
    "    OUTPUT = f\"/home/jupyter/output/distribution/\"\n",
    "    SEED = 0\n",
    "    N_FOLD = 4\n",
    "    TARGETS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    \n",
    "    MODEL_NAME = \"microsoft/deberta-v3-xsmall\"\n",
    "    TOKENIZER = None\n",
    "    MAX_LEN = 512\n",
    "    GRAD_CHECKPOINT = False\n",
    "    \n",
    "    N_EPOCH = 16\n",
    "    N_WORKER = 4\n",
    "    ENCODER_LR = 1e-4\n",
    "    DECODER_LR = 5e-3\n",
    "\n",
    "    EPS = 1e-6\n",
    "    BETAS = (0.9, 0.999)\n",
    "    WEIGHT_DECAY = 0.1\n",
    "    N_WARMUP = 0\n",
    "    N_CYCLES = 0.5\n",
    "    \n",
    "    BS = 64\n",
    "    ACCUMLATION = 1\n",
    "    \n",
    "    GRAD_NORM = 0.1\n",
    "    \n",
    "    MASK_RATIO = 0.1\n",
    "    \n",
    "    SKIP_FOLDS = [None]\n",
    "    LOCAL_SEED = 0\n",
    "\n",
    "!mkdir -p {CFG.OUTPUT}\n",
    "!kaggle datasets init -p {CFG.OUTPUT}\n",
    "\n",
    "with open(f'{CFG.OUTPUT}/dataset-metadata.json', 'r') as f:\n",
    "    d = json.load(f)\n",
    "t = f'FB3 distribution last'\n",
    "\n",
    "d['title'] = t\n",
    "d['id'] = f'takamichitoda/'+ t.replace(' ', '-')\n",
    "print(d)\n",
    "with open(f'{CFG.OUTPUT}/dataset-metadata.json', 'w') as f:\n",
    "    json.dump(d, f)\n",
    "del d\n",
    "\n",
    "s = {k:v for k, v in vars(CFG).items() if \"__\" != k[:2]}\n",
    "with open(f'{CFG.OUTPUT}/setting.json', 'w') as f:\n",
    "    json.dump(s, f)\n",
    "del s\n",
    "\n",
    "!rm -rf {CFG.OUTPUT}/tokenizer*\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)\n",
    "TOKENIZER.save_pretrained(CFG.OUTPUT+'tokenizer/')\n",
    "CFG.TOKENIZER = TOKENIZER\n",
    "del TOKENIZER\n",
    "!zip -r tokenizer.zip {CFG.OUTPUT}/tokenizer\n",
    "!mv tokenizer.zip {CFG.OUTPUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193a945f-85e4-4793-8157-77f7d6948c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  fold  \n",
       "0     3.5         3.0          3.0      4.0          3.0     2  \n",
       "1     2.5         3.0          2.0      2.0          2.5     3  \n",
       "2     3.5         3.0          3.0      3.0          2.5     0  \n",
       "3     4.5         4.5          4.5      4.0          5.0     0  \n",
       "4     3.0         3.0          3.0      2.5          2.5     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.018248</td>\n",
       "      <td>2.975119</td>\n",
       "      <td>3.121308</td>\n",
       "      <td>3.170475</td>\n",
       "      <td>3.175702</td>\n",
       "      <td>2.880757</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.706631</td>\n",
       "      <td>2.599061</td>\n",
       "      <td>2.869723</td>\n",
       "      <td>2.708271</td>\n",
       "      <td>2.475758</td>\n",
       "      <td>2.625469</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>2.832288</td>\n",
       "      <td>2.960374</td>\n",
       "      <td>3.035029</td>\n",
       "      <td>2.946630</td>\n",
       "      <td>2.983717</td>\n",
       "      <td>3.079813</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>3.739573</td>\n",
       "      <td>3.700710</td>\n",
       "      <td>3.771889</td>\n",
       "      <td>3.764411</td>\n",
       "      <td>3.721735</td>\n",
       "      <td>3.855008</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.491964</td>\n",
       "      <td>2.439298</td>\n",
       "      <td>2.848604</td>\n",
       "      <td>2.701830</td>\n",
       "      <td>2.642546</td>\n",
       "      <td>2.390833</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...  3.018248   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...  2.706631   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...  2.832288   \n",
       "3  003885A45F42  The best time in life is when you become yours...  3.739573   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...  2.491964   \n",
       "\n",
       "     syntax  vocabulary  phraseology   grammar  conventions  fold  origin  \n",
       "0  2.975119    3.121308     3.170475  3.175702     2.880757     2    True  \n",
       "1  2.599061    2.869723     2.708271  2.475758     2.625469     3    True  \n",
       "2  2.960374    3.035029     2.946630  2.983717     3.079813     0    True  \n",
       "3  3.700710    3.771889     3.764411  3.721735     3.855008     0    True  \n",
       "4  2.439298    2.848604     2.701830  2.642546     2.390833     2    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_train_df = pd.read_csv(f\"{CFG.INPUT}/train.csv\")\n",
    "\n",
    "cv = MultilabelStratifiedKFold(n_splits=CFG.N_FOLD, shuffle=True, random_state=CFG.SEED)\n",
    "for n, (train_index, valid_index) in enumerate(cv.split(org_train_df, org_train_df[CFG.TARGETS])):\n",
    "    org_train_df.loc[valid_index, 'fold'] = int(n)\n",
    "org_train_df['fold'] = org_train_df['fold'].astype(int)\n",
    "\n",
    "display(org_train_df.head())\n",
    "\n",
    "text_for_distillation_df = pd.read_csv('fb3-distillation-data-final/AVG_pseudo.csv')\n",
    "\n",
    "display(text_for_distillation_df.head())\n",
    "\n",
    "(org_train_df['fold'] == text_for_distillation_df.query('origin')['fold']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d39237-3e2e-4812-ae34-099caebe478e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 7984, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pseudo_vecs = np.load(\"fb3-distillation-data-final/all_pseudo.npy\")\n",
    "all_pseudo_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "350b0d36-2a89-4ec2-abe0-d75175f2cd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 7984, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pseudo_vecs_fold = np.stack([all_pseudo_vecs[i*4:i*4+4, :, :] for i in range(10)])\n",
    "all_pseudo_vecs_fold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8fb7f0-9551-4954-b3e5-c91e36519786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0354385, 2.9816506, 3.130321 , 3.1700034, 3.1622906, 2.8736572],\n",
       "       [2.664759 , 2.5898054, 2.8661423, 2.7049441, 2.4630837, 2.6250384],\n",
       "       [2.8375874, 2.9681032, 3.0402222, 2.9363437, 2.9911904, 3.106997 ],\n",
       "       ...,\n",
       "       [3.42127  , 3.4127638, 3.5362985, 3.555582 , 3.79319  , 3.5025253],\n",
       "       [3.8772469, 3.7908058, 3.814385 , 3.8354151, 4.017723 , 3.8829298],\n",
       "       [4.059508 , 4.0865126, 4.23125  , 4.257974 , 4.4012203, 4.069358 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(all_pseudo_vecs_fold.mean(1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a928efcd-1063-4cde-8dcb-0f8b4e3a5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_ID = 128000\n",
    "def masking(inputs):\n",
    "    is_special_token = (np.array(inputs[\"input_ids\"]) == 1).astype(int) + (np.array(inputs[\"input_ids\"]) == 2).astype(int)\n",
    "    mask = np.array([random.random() < CFG.MASK_RATIO for _ in range(CFG.MAX_LEN)])\n",
    "    mask = mask * np.array(inputs[\"attention_mask\"]) * (1 - is_special_token)\n",
    "    masking_ids = np.where(mask != 0, MASK_ID, inputs[\"input_ids\"])\n",
    "    return masking_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80536c2-8905-4160-b123-fe96820bfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FB3Dataset(Dataset):\n",
    "    def __init__(self, df, train=False):\n",
    "        self.texts = df['full_text'].values\n",
    "        self.labels = df[CFG.TARGETS].values\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = CFG.TOKENIZER.encode_plus(\n",
    "            self.texts[item], \n",
    "            return_tensors=None, \n",
    "            add_special_tokens=True, \n",
    "            max_length=CFG.MAX_LEN,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        #if self.train:\n",
    "        #    inputs[\"input_ids\"] = masking(inputs)\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype=torch.long) \n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        return inputs, label\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d7110c-ec91-4eaa-9d29-9524425af1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FB3Dataset_v2(Dataset):\n",
    "    def __init__(self, df, train=False):\n",
    "        self.texts = df['full_text'].values\n",
    "        self.labels = df[CFG.TARGETS].values\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.train:\n",
    "            inputs = CFG.TOKENIZER.encode_plus(\n",
    "                self.texts[item], \n",
    "                return_tensors=None, \n",
    "                add_special_tokens = False,\n",
    "            )\n",
    "\n",
    "            if len(inputs['input_ids']) > CFG.MAX_LEN:\n",
    "                l = CFG.MAX_LEN - 2\n",
    "                start_i = random.sample(list(range(len(inputs['input_ids']) - l)), 1)\n",
    "                start_i = start_i[0]\n",
    "                inputs['input_ids'] = [1] + inputs['input_ids'][start_i:start_i+l] + [2]\n",
    "                inputs['attention_mask'] = [1] + inputs['attention_mask'][start_i:start_i+l] + [1]\n",
    "                inputs['token_type_ids'] = [0] + inputs['token_type_ids'][start_i:start_i+l] + [0]\n",
    "\n",
    "            pad = [0] * (CFG.MAX_LEN - len(inputs['input_ids']))\n",
    "            inputs['input_ids'] += pad\n",
    "            inputs['attention_mask'] += pad\n",
    "            inputs['token_type_ids'] += pad\n",
    "        else:\n",
    "            inputs = CFG.TOKENIZER.encode_plus(\n",
    "                self.texts[item], \n",
    "                return_tensors=None, \n",
    "                add_special_tokens=True, \n",
    "                max_length=CFG.MAX_LEN,\n",
    "                pad_to_max_length=True,\n",
    "                truncation=True\n",
    "            )\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype=torch.long) \n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f0fdde-a695-4889-bd64-424f31d1aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "        self.config.hidden_dropout = 0.\n",
    "        self.config.hidden_dropout_prob = 0.\n",
    "        self.config.attention_dropout = 0.\n",
    "        self.config.attention_probs_dropout_prob = 0.\n",
    "        self.config.num_hidden_layers = 4\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "\n",
    "        if CFG.GRAD_CHECKPOINT:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "            \n",
    "        \n",
    "        layer_start = self.config.num_hidden_layers\n",
    "        self.layer_pool = WeightedLayerPooling(\n",
    "            self.config.num_hidden_layers, \n",
    "            layer_start=layer_start, layer_weights=None\n",
    "        )\n",
    "        #self.lstm = nn.LSTM(self.config.hidden_size, self.config.hidden_size, batch_first=True)\n",
    "        \n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.config.hidden_size, 6),\n",
    "        )\n",
    "        self._init_weights(self.fc)\n",
    "        #self.fc1 = nn.Sequential(\n",
    "        #    nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Linear(self.config.hidden_size, 6),\n",
    "        #)\n",
    "        #self._init_weights(self.fc1)\n",
    "        #self.fc2 = nn.Sequential(\n",
    "        #    nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Linear(self.config.hidden_size, 6),\n",
    "        #)\n",
    "        #self._init_weights(self.fc2)\n",
    "        \n",
    "        # reinit_layers\n",
    "        reinit_layer = 1\n",
    "        if reinit_layer > 0:\n",
    "            for layer in self.model.encoder.layer[-reinit_layer:]:\n",
    "                for module in layer.modules():\n",
    "                    if isinstance(module, nn.Linear):\n",
    "                        module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "                        if module.bias is not None:\n",
    "                            module.bias.data.zero_()\n",
    "                    elif isinstance(module, nn.Embedding):\n",
    "                        module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "                        if module.padding_idx is not None:\n",
    "                            module.weight.data[module.padding_idx].zero_()\n",
    "                    elif isinstance(module, nn.LayerNorm):\n",
    "                        module.bias.data.zero_()\n",
    "                        module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        pooling_embeddings = outputs[0]\n",
    "        #all_hidden_states = torch.stack(outputs[1])\n",
    "        #pooling_embeddings = self.layer_pool(all_hidden_states)\n",
    "        \n",
    "        #out, _ = self.lstm(pooling_embeddings, None)\n",
    "        #pooling_embeddings = out #.swapaxes(1, 2)\n",
    "\n",
    "        feature = self.pool(pooling_embeddings, inputs['attention_mask'])\n",
    "        #feature = pooling_embeddings[:, 0, :]\n",
    "        \n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "        #output1 = self.fc1(feature)\n",
    "        #output2 = self.fc2(feature)\n",
    "        #return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04965d1e-61a2-43a2-b0d8-772da4bac40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f34d456-be3b-445a-878e-2315c212a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "         'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters\n",
    "\"\"\"\n",
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    group1=['layer.0.']\n",
    "    group2=['layer.1.']    \n",
    "    group3=['layer.2.','layer.3.']\n",
    "    group_all=['layer.0.','layer.1.','layer.2.','layer.3.']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/4.0},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr/2.0},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/4.0},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr/2.0},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr': decoder_lr, \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daaa179d-8ecb-4891-926e-d98509d46286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(epoch, train_loader, student, criterion, optimizer, scheduler):\n",
    "    student.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=is_gpu):\n",
    "            y_preds = student(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            #y_preds1, y_preds2 = student(inputs)\n",
    "            #loss1 = criterion(y_preds1, torch.ceil(labels))\n",
    "            #loss2 = criterion(y_preds2, torch.floor(labels))\n",
    "            #loss = loss1 + loss2\n",
    "\n",
    "\n",
    "        if CFG.ACCUMLATION > 1:\n",
    "            loss = loss / CFG.ACCUMLATION\n",
    "            \n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(student.parameters(), CFG.GRAD_NORM)\n",
    "        \n",
    "        if (step + 1) % CFG.ACCUMLATION == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            scheduler.step()\n",
    "                \n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            #y_preds1, y_preds2 = model(inputs)\n",
    "            #y_preds = (y_preds1 + y_preds2) / 2\n",
    "            loss = criterion(y_preds, labels)\n",
    "            \n",
    "        if CFG.ACCUMLATION > 1:\n",
    "            loss = loss / CFG.ACCUMLATION\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c16b0639-ab8c-4a74-9191-6c7fd8c3baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "def swa_fn(epoch, train_loader, model, swa_model, criterion, optimizer, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=is_gpu):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            \n",
    "        if CFG.ACCUMLATION > 1:\n",
    "            loss = loss / CFG.ACCUMLATION\n",
    "            \n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.GRAD_NORM)\n",
    "        \n",
    "        if (step + 1) % CFG.ACCUMLATION == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            swa_model.update_parameters(model)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            scheduler.step()\n",
    "                \n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d51a3689-7995-416f-94b5-bc9846bd9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, eps, mask):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = nn.MSELoss(reduction='none')(outputs, targets)\n",
    "\n",
    "        if self.mask is None:\n",
    "            loss = torch.mean(torch.clamp(loss - self.eps**2, min=0))\n",
    "        else:\n",
    "            loss = torch.mean(torch.clamp(loss - self.eps**2, min=0, max=self.mask**2))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52bee9a-87da-4b27-b4dd-cd5b66b49756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "class PriorWD(Optimizer):\n",
    "    def __init__(self, optim, use_prior_wd=False, exclude_last_group=True):\n",
    "        super(PriorWD, self).__init__(optim.param_groups, optim.defaults)\n",
    "        self.param_groups = optim.param_groups\n",
    "        self.optim = optim\n",
    "        self.use_prior_wd = use_prior_wd\n",
    "        self.exclude_last_group = exclude_last_group\n",
    "        self.weight_decay_by_group = []\n",
    "        for i, group in enumerate(self.param_groups):\n",
    "            self.weight_decay_by_group.append(group[\"weight_decay\"])\n",
    "            group[\"weight_decay\"] = 0\n",
    "\n",
    "        self.prior_params = {}\n",
    "        for i, group in enumerate(self.param_groups):\n",
    "            for p in group[\"params\"]:\n",
    "                self.prior_params[id(p)] = p.detach().clone()\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        if self.use_prior_wd:\n",
    "            for i, group in enumerate(self.param_groups):\n",
    "                for p in group[\"params\"]:\n",
    "                    if self.exclude_last_group and i == len(self.param_groups):\n",
    "                        p.data.add_(-group[\"lr\"] * self.weight_decay_by_group[i], p.data)\n",
    "                    else:\n",
    "                        p.data.add_(\n",
    "                            -group[\"lr\"] * self.weight_decay_by_group[i], p.data - self.prior_params[id(p)],\n",
    "                        )\n",
    "        loss = self.optim.step(closure)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_distance_to_prior(self, param):\n",
    "        assert id(param) in self.prior_params, \"parameter not in PriorWD optimizer\"\n",
    "        return (param.data - self.prior_params[id(param)]).pow(2).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d953faad-aaca-41fa-9283-50b624cf7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(fold, seed):\n",
    "    if fold == \"ALL\":\n",
    "        text_for_distillation_df[CFG.TARGETS] = all_pseudo_vecs_fold.mean(0).mean(0)\n",
    "        valid_df = org_train_df\n",
    "        train_df = text_for_distillation_df\n",
    "    else:\n",
    "        text_for_distillation_df[CFG.TARGETS] = all_pseudo_vecs_fold[:, fold, :, :].mean(0)\n",
    "        #text_for_distillation_df[CFG.TARGETS] = all_pseudo_vecs_fold[[1,2,3,5,6,8], fold, :, :].mean(0)\n",
    "        #text_for_distillation_df[CFG.TARGETS] = all_pseudo_vecs_fold[[0,1,2], fold, :, :].mean(0)\n",
    "        valid_df = org_train_df.query(f\"fold=={fold}\")\n",
    "        train_df = text_for_distillation_df.query(f\"fold!={fold}\")\n",
    "\n",
    "    valid_labels = valid_df[CFG.TARGETS].values\n",
    "    train_dataset = FB3Dataset(train_df, train=True)\n",
    "    valid_dataset = FB3Dataset(valid_df, train=False)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.BS,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.N_WORKER, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.BS,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.N_WORKER, pin_memory=True, drop_last=False)\n",
    "\n",
    "    student = CustomModel(CFG.MODEL_NAME)\n",
    "    torch.save(student.config, CFG.OUTPUT + 'config.pth')\n",
    "    student.to(device)\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(student,\n",
    "                                                encoder_lr=CFG.ENCODER_LR, \n",
    "                                                decoder_lr=CFG.DECODER_LR,\n",
    "                                                weight_decay=CFG.WEIGHT_DECAY)\n",
    "\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.ENCODER_LR, eps=CFG.EPS, betas=CFG.BETAS, correct_bias=True)\n",
    "    optimizer = PriorWD(optimizer, use_prior_wd=True)\n",
    "\n",
    "    num_train_steps = int(len(train_dataset) / CFG.BS * CFG.N_EPOCH)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=CFG.N_WARMUP, num_training_steps=num_train_steps, num_cycles=CFG.N_CYCLES\n",
    "    )\n",
    "    #criterion = nn.SmoothL1Loss(reduction='mean', beta=1.0)\n",
    "    #criterion = nn.HuberLoss(reduction='mean', delta=1.0)\n",
    "    #criterion = svm_loss\n",
    "    criterion = CustomLoss(eps=0.1, mask=None)\n",
    "\n",
    "    swa_model = AveragedModel(student)\n",
    "    swa_scheduler = SWALR(optimizer, swa_lr=1e-6)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_predictions = None\n",
    "    results = []\n",
    "    for epoch in range(CFG.N_EPOCH):\n",
    "        if epoch == 7:\n",
    "            mask = 1.5\n",
    "            print(f'eps=0.0, mask={mask}')\n",
    "            criterion = CustomLoss(eps=0.0, mask=mask)\n",
    "\n",
    "        if epoch < 45:\n",
    "            avg_loss = train_fn(epoch, train_loader, student, criterion, optimizer, scheduler)\n",
    "            avg_val_loss, predictions = valid_fn(valid_loader, student, criterion)\n",
    "        else:\n",
    "            avg_loss = swa_fn(epoch, train_loader, student, swa_model, criterion, optimizer, swa_scheduler)\n",
    "            avg_val_loss, predictions = valid_fn(valid_loader, swa_model, criterion)\n",
    "\n",
    "        score, _ = get_score(valid_labels, predictions)\n",
    "        \n",
    "        if best_score > score:\n",
    "            best_score = score\n",
    "            best_predictions = predictions\n",
    "            torch.save({'model': student.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                         f\"{CFG.OUTPUT}/{CFG.MODEL_NAME.replace('/', '-')}_seed{seed}_fold{fold}_best.pth\")\n",
    "        print(f\"[Fold-{fold}] epoch-{epoch}: score={score}\")\n",
    "        results.append((fold, epoch, score, best_score))\n",
    "\n",
    "        if fold == \"ALL\" and epoch > 0:\n",
    "            torch.save({'model': student.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        f\"{CFG.OUTPUT}/{CFG.MODEL_NAME.replace('/', '-')}_seed{seed}_fold{fold}_epoch{epoch}.pth\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    return best_score, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6cf0506-65f8-4765-ba48-9a64c889b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed):\n",
    "    scores = []\n",
    "    results_lst = []\n",
    "    for fold in range(CFG.N_FOLD):\n",
    "        if fold in CFG.SKIP_FOLDS:\n",
    "            continue\n",
    "        seed_everything(seed)\n",
    "        score, results = train_loop(fold, seed)\n",
    "        scores.append(score)\n",
    "        results_lst += results\n",
    "    print(scores)\n",
    "    print(sum(scores) / CFG.N_FOLD)\n",
    "\n",
    "    pd.DataFrame(results_lst, columns=['fold',  'epoch', 'score', 'best_score']).to_csv(f\"{CFG.OUTPUT}/result.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3094bc2c-65fe-4281-bb85-adee15a27cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "#    main(CFG.LOCAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72243ecf-75e7-46ec-bbd2-9722c220d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-xsmall were not used when initializing DebertaV2Model: ['deberta.encoder.layer.7.intermediate.dense.weight', 'deberta.encoder.layer.6.attention.output.LayerNorm.weight', 'deberta.encoder.layer.6.output.LayerNorm.bias', 'deberta.encoder.layer.5.output.LayerNorm.bias', 'deberta.encoder.layer.11.attention.output.dense.weight', 'deberta.encoder.layer.4.attention.self.query_proj.weight', 'deberta.encoder.layer.7.output.LayerNorm.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.weight', 'deberta.encoder.layer.4.attention.self.value_proj.bias', 'deberta.encoder.layer.4.output.LayerNorm.bias', 'deberta.encoder.layer.10.intermediate.dense.weight', 'mask_predictions.LayerNorm.bias', 'deberta.encoder.layer.11.attention.self.value_proj.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.weight', 'deberta.encoder.layer.8.attention.self.value_proj.bias', 'deberta.encoder.layer.11.intermediate.dense.bias', 'deberta.encoder.layer.10.attention.self.query_proj.weight', 'deberta.encoder.layer.4.attention.output.dense.weight', 'deberta.encoder.layer.8.output.dense.weight', 'deberta.encoder.layer.9.attention.output.dense.bias', 'deberta.encoder.layer.4.attention.self.key_proj.bias', 'deberta.encoder.layer.6.attention.self.value_proj.bias', 'deberta.encoder.layer.9.attention.self.query_proj.bias', 'deberta.encoder.layer.10.output.dense.weight', 'deberta.encoder.layer.8.attention.output.dense.bias', 'deberta.encoder.layer.10.attention.self.key_proj.weight', 'lm_predictions.lm_head.dense.bias', 'deberta.encoder.layer.6.intermediate.dense.bias', 'deberta.encoder.layer.8.attention.self.query_proj.weight', 'deberta.encoder.layer.10.attention.self.value_proj.bias', 'deberta.encoder.layer.4.intermediate.dense.weight', 'deberta.encoder.layer.10.output.LayerNorm.bias', 'deberta.encoder.layer.10.intermediate.dense.bias', 'deberta.encoder.layer.11.attention.output.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.bias', 'deberta.encoder.layer.11.attention.self.key_proj.bias', 'deberta.encoder.layer.5.attention.self.value_proj.weight', 'deberta.encoder.layer.10.output.dense.bias', 'deberta.encoder.layer.11.output.dense.weight', 'deberta.encoder.layer.8.intermediate.dense.weight', 'deberta.encoder.layer.10.output.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'deberta.encoder.layer.10.attention.self.value_proj.weight', 'mask_predictions.classifier.bias', 'deberta.encoder.layer.6.attention.self.query_proj.bias', 'deberta.encoder.layer.4.output.dense.bias', 'deberta.encoder.layer.7.attention.self.value_proj.bias', 'deberta.encoder.layer.5.attention.self.key_proj.weight', 'mask_predictions.classifier.weight', 'deberta.encoder.layer.6.attention.self.query_proj.weight', 'deberta.encoder.layer.7.attention.self.key_proj.bias', 'deberta.encoder.layer.6.attention.output.dense.bias', 'deberta.encoder.layer.10.attention.self.key_proj.bias', 'deberta.encoder.layer.7.intermediate.dense.bias', 'deberta.encoder.layer.8.attention.self.value_proj.weight', 'deberta.encoder.layer.7.output.dense.weight', 'deberta.encoder.layer.9.attention.self.key_proj.weight', 'deberta.encoder.layer.6.intermediate.dense.weight', 'deberta.encoder.layer.4.attention.self.value_proj.weight', 'deberta.encoder.layer.9.attention.self.query_proj.weight', 'deberta.encoder.layer.6.output.dense.weight', 'deberta.encoder.layer.11.attention.output.dense.bias', 'deberta.encoder.layer.9.intermediate.dense.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'deberta.encoder.layer.7.attention.self.query_proj.bias', 'deberta.encoder.layer.6.attention.self.value_proj.weight', 'deberta.encoder.layer.6.output.dense.bias', 'deberta.encoder.layer.5.attention.self.query_proj.weight', 'deberta.encoder.layer.5.output.dense.bias', 'deberta.encoder.layer.7.attention.self.value_proj.weight', 'deberta.encoder.layer.8.intermediate.dense.bias', 'deberta.encoder.layer.9.attention.output.dense.weight', 'deberta.embeddings.word_embeddings._weight', 'deberta.encoder.layer.5.attention.output.dense.bias', 'deberta.encoder.layer.9.attention.self.key_proj.bias', 'deberta.encoder.layer.11.attention.self.query_proj.weight', 'deberta.encoder.layer.6.output.LayerNorm.weight', 'deberta.encoder.layer.7.attention.output.dense.weight', 'deberta.encoder.layer.7.attention.output.dense.bias', 'deberta.encoder.layer.9.output.LayerNorm.weight', 'deberta.encoder.layer.5.output.LayerNorm.weight', 'deberta.encoder.layer.6.attention.self.key_proj.bias', 'deberta.encoder.layer.7.output.LayerNorm.bias', 'deberta.encoder.layer.10.attention.output.dense.bias', 'deberta.encoder.layer.5.attention.self.value_proj.bias', 'deberta.encoder.layer.4.output.dense.weight', 'deberta.encoder.layer.5.attention.output.dense.weight', 'deberta.encoder.layer.11.output.dense.bias', 'deberta.encoder.layer.4.attention.self.key_proj.weight', 'lm_predictions.lm_head.dense.weight', 'deberta.encoder.layer.8.attention.self.query_proj.bias', 'deberta.encoder.layer.10.attention.self.query_proj.bias', 'deberta.encoder.layer.4.attention.output.dense.bias', 'deberta.encoder.layer.4.output.LayerNorm.weight', 'deberta.encoder.layer.9.attention.self.value_proj.bias', 'deberta.encoder.layer.9.output.dense.bias', 'deberta.encoder.layer.5.attention.output.LayerNorm.weight', 'deberta.encoder.layer.8.output.dense.bias', 'deberta.encoder.layer.4.attention.self.query_proj.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'deberta.encoder.layer.8.output.LayerNorm.weight', 'deberta.encoder.layer.5.intermediate.dense.bias', 'deberta.encoder.layer.9.attention.self.value_proj.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.bias', 'deberta.encoder.layer.8.attention.output.dense.weight', 'deberta.encoder.layer.10.attention.output.LayerNorm.weight', 'deberta.encoder.layer.5.attention.self.query_proj.bias', 'deberta.encoder.layer.5.output.dense.weight', 'deberta.encoder.layer.11.attention.self.key_proj.weight', 'deberta.encoder.layer.7.attention.self.key_proj.weight', 'deberta.encoder.layer.8.attention.self.key_proj.weight', 'deberta.encoder.layer.8.output.LayerNorm.bias', 'deberta.encoder.layer.9.output.dense.weight', 'deberta.encoder.layer.7.output.dense.bias', 'mask_predictions.dense.weight', 'deberta.encoder.layer.9.intermediate.dense.bias', 'deberta.encoder.layer.10.attention.output.dense.weight', 'deberta.encoder.layer.4.intermediate.dense.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.weight', 'deberta.encoder.layer.5.attention.output.LayerNorm.bias', 'deberta.encoder.layer.11.intermediate.dense.weight', 'deberta.encoder.layer.5.attention.self.key_proj.bias', 'deberta.encoder.layer.5.intermediate.dense.weight', 'deberta.encoder.layer.8.attention.self.key_proj.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.bias', 'deberta.encoder.layer.11.output.LayerNorm.weight', 'deberta.encoder.layer.11.attention.self.query_proj.bias', 'deberta.encoder.layer.4.attention.output.LayerNorm.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.bias', 'deberta.encoder.layer.7.attention.self.query_proj.weight', 'deberta.encoder.layer.11.attention.self.value_proj.bias', 'deberta.encoder.layer.6.attention.output.dense.weight', 'deberta.encoder.layer.6.attention.self.key_proj.weight', 'deberta.encoder.layer.6.attention.output.LayerNorm.bias', 'deberta.encoder.layer.11.output.LayerNorm.bias', 'deberta.encoder.layer.9.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0aad76682c547d0b472c6e8ed41e15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-0: score=0.5132259895808844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcee174850045a4ad782ed05c4747b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-1: score=0.4848833539141923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4138024d1164ac698cff5cd9d7b3aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-2: score=0.4939199873921862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042416ba419b4cafa541d5fbe42038dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-3: score=0.47949929313301914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa42fa54f444eb98c59a187b77093cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-4: score=0.46986867856192305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50388e3afa054ffd9858ebbaaa4829a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-5: score=0.460802145826348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c67431a853a4c4d8eeaa390784dea3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-6: score=0.45923104084146465\n",
      "eps=0.0, mask=1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3123225c6024e8cb5c0ac3c5fd12ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-7: score=0.4684564534171394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f0f517ba0f4fd3a1fa66f1be936d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-8: score=0.4568428280442017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e651fa3d08eb4e08bf02613c7a9d96b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-9: score=0.45839842399443725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4e79a75b704069b3ca01b56379999a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-10: score=0.4468800707690845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e057dadc904b4643aa7ec65a8701403c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-11: score=0.4481169937280405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a257609d05324cd19bedf688d69957b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-12: score=0.44458947634972557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8316a286f84e70b250afc601c5e65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-13: score=0.44607483599008174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53acea8c3ce40cdacb3db3b7a777be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-14: score=0.4418350059457903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5738777abe6a4f5ca846d1d88b5697fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-ALL] epoch-15: score=0.44192090146740876\n",
      "0.4418350059457903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>score</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513226</td>\n",
       "      <td>0.513226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484883</td>\n",
       "      <td>0.484883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.493920</td>\n",
       "      <td>0.484883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALL</td>\n",
       "      <td>3</td>\n",
       "      <td>0.479499</td>\n",
       "      <td>0.479499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469869</td>\n",
       "      <td>0.469869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALL</td>\n",
       "      <td>5</td>\n",
       "      <td>0.460802</td>\n",
       "      <td>0.460802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALL</td>\n",
       "      <td>6</td>\n",
       "      <td>0.459231</td>\n",
       "      <td>0.459231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALL</td>\n",
       "      <td>7</td>\n",
       "      <td>0.468456</td>\n",
       "      <td>0.459231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALL</td>\n",
       "      <td>8</td>\n",
       "      <td>0.456843</td>\n",
       "      <td>0.456843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALL</td>\n",
       "      <td>9</td>\n",
       "      <td>0.458398</td>\n",
       "      <td>0.456843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ALL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.446880</td>\n",
       "      <td>0.446880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ALL</td>\n",
       "      <td>11</td>\n",
       "      <td>0.448117</td>\n",
       "      <td>0.446880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ALL</td>\n",
       "      <td>12</td>\n",
       "      <td>0.444589</td>\n",
       "      <td>0.444589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ALL</td>\n",
       "      <td>13</td>\n",
       "      <td>0.446075</td>\n",
       "      <td>0.444589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ALL</td>\n",
       "      <td>14</td>\n",
       "      <td>0.441835</td>\n",
       "      <td>0.441835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALL</td>\n",
       "      <td>15</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.441835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch     score  best_score\n",
       "0   ALL      0  0.513226    0.513226\n",
       "1   ALL      1  0.484883    0.484883\n",
       "2   ALL      2  0.493920    0.484883\n",
       "3   ALL      3  0.479499    0.479499\n",
       "4   ALL      4  0.469869    0.469869\n",
       "5   ALL      5  0.460802    0.460802\n",
       "6   ALL      6  0.459231    0.459231\n",
       "7   ALL      7  0.468456    0.459231\n",
       "8   ALL      8  0.456843    0.456843\n",
       "9   ALL      9  0.458398    0.456843\n",
       "10  ALL     10  0.446880    0.446880\n",
       "11  ALL     11  0.448117    0.446880\n",
       "12  ALL     12  0.444589    0.444589\n",
       "13  ALL     13  0.446075    0.444589\n",
       "14  ALL     14  0.441835    0.441835\n",
       "15  ALL     15  0.441921    0.441835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_everything(0)\n",
    "score, results = train_loop(\"ALL\", 0)\n",
    "print(score)\n",
    "\n",
    "df = pd.DataFrame(results, columns=['fold',  'epoch', 'score', 'best_score'])\n",
    "df.columns=['fold',  'epoch', 'score', 'best_score']\n",
    "df.to_csv(f\"{CFG.OUTPUT}/result_all.csv\", index=None)\n",
    "display(df)\n",
    "\n",
    "df[['score', 'best_score']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7754a72-8897-4700-a4fd-63feed7ae4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch15.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:09<00:00, 23.4MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch15.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch3.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:07<00:00, 29.4MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch3.pth (216MB)\n",
      "Starting upload for file config.pth\n",
      "100%|██████████████████████████████████████| 2.55k/2.55k [00:01<00:00, 1.40kB/s]\n",
      "Upload successful: config.pth (3KB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch5.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:06<00:00, 32.7MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch5.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch11.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:07<00:00, 28.4MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch11.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_best.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:09<00:00, 23.3MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_best.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch2.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:08<00:00, 26.6MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch2.pth (216MB)\n",
      "Skipping folder: tokenizer; use '--dir-mode' to upload folders\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch7.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:08<00:00, 28.0MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch7.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch12.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:09<00:00, 22.9MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch12.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch4.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:07<00:00, 29.2MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch4.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch9.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:12<00:00, 18.4MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch9.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch10.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:11<00:00, 20.2MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch10.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch14.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:13<00:00, 16.9MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch14.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch13.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:11<00:00, 19.3MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch13.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch1.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:07<00:00, 30.1MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch1.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch6.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:09<00:00, 23.1MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch6.pth (216MB)\n",
      "Starting upload for file setting.json\n",
      "100%|████████████████████████████████████████████| 610/610 [00:01<00:00, 314B/s]\n",
      "Upload successful: setting.json (610B)\n",
      "Starting upload for file tokenizer.zip\n",
      "100%|██████████████████████████████████████| 3.04M/3.04M [00:02<00:00, 1.54MB/s]\n",
      "Upload successful: tokenizer.zip (3MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_fold1_best.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:09<00:00, 22.8MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_fold1_best.pth (216MB)\n",
      "Starting upload for file result_all.csv\n",
      "100%|████████████████████████████████████████████| 749/749 [00:01<00:00, 402B/s]\n",
      "Upload successful: result_all.csv (749B)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_foldALL_epoch8.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:09<00:00, 23.5MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_foldALL_epoch8.pth (216MB)\n",
      "Starting upload for file microsoft-deberta-v3-xsmall_seed0_fold0_best.pth\n",
      "100%|████████████████████████████████████████| 216M/216M [00:08<00:00, 28.3MB/s]\n",
      "Upload successful: microsoft-deberta-v3-xsmall_seed0_fold0_best.pth (216MB)\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/takamichitoda/FB3-distribution-last\n"
     ]
    }
   ],
   "source": [
    "#!kaggle datasets create -p {CFG.OUTPUT}\n",
    "!kaggle datasets version -p {CFG.OUTPUT} -m 'all tune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a58e8d-b883-4144-aa09-5466cc48a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {CFG.OUTPUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81b5ac-7dbc-47d9-9161-4f134cc77bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
