{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a5d87b-d5d4-4486-a353-88284be30804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 10 09:45:47 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P0    25W /  70W |      0MiB / 15360MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7255a110-17df-4771-bf1d-f9a2bdb8691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API 1.5.12\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p .kaggle\n",
    "!cp \"./kaggle.json\" .kaggle/\n",
    "!chmod 600 .kaggle/kaggle.json\n",
    "!cp -r .kaggle /root\n",
    "\n",
    "!kaggle -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68a6b01-ae1b-4665-9595-f731568ab779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification==0.1.7\n",
      "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.21.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.0.1)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification==0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6281df0d-d301-4bd9-859d-08165783c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "transformers.__version__: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "is_gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_gpu else 'cpu')\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=is_gpu)\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82aabb7-f424-4f63-b131-a84035f1441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    EXP = \"exp186\"\n",
    "    INPUT = \"/home/jupyter/feedback-prize-english-language-learning\"\n",
    "    OUTPUT = f\"/home/jupyter/{EXP}/\"\n",
    "    SEED = 0\n",
    "    N_FOLD = 4\n",
    "    TARGETS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "    MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "    TOKENIZER = None\n",
    "    MAX_LEN = 1428\n",
    "    GRAD_CHECKPOINT = True\n",
    "    \n",
    "    N_EPOCH = 4\n",
    "    N_WORKER = 4\n",
    "    ENCODER_LR = 5e-6\n",
    "    DECODER_LR = 1e-4\n",
    "    EPS = 1e-6\n",
    "    BETAS = (0.9, 0.999)\n",
    "    WEIGHT_DECAY = 0.1\n",
    "    N_WARMUP = 0\n",
    "    N_CYCLES = 0.5\n",
    "    \n",
    "    BS = 8\n",
    "    ACCUMLATION = 1\n",
    "    \n",
    "    GRAD_NORM = 0.1\n",
    "    \n",
    "    ADV_EPS = 1e-4\n",
    "    ADV_LR = 1e-4\n",
    "    ADV_START = 2\n",
    "    \n",
    "    FGM_EPS = 1e-1\n",
    "    FGM_END = float(\"inf\")\n",
    "    \n",
    "    SKIP_FOLDS = [None]\n",
    "    LOCAL_SEED = 0\n",
    "    \n",
    "    ROUND = ['up', 'cut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4466da71-3fe8-47cc-99df-3638d530dde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  fold  \n",
       "0     3.5         3.0          3.0      4.0          3.0     2  \n",
       "1     2.5         3.0          2.0      2.0          2.5     3  \n",
       "2     3.5         3.0          3.0      3.0          2.5     0  \n",
       "3     4.5         4.5          4.5      4.0          5.0     0  \n",
       "4     3.0         3.0          3.0      2.5          2.5     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"{CFG.INPUT}/train.csv\")\n",
    "\n",
    "cv = MultilabelStratifiedKFold(n_splits=CFG.N_FOLD, shuffle=True, random_state=CFG.SEED)\n",
    "for n, (train_index, valid_index) in enumerate(cv.split(train_df, train_df[CFG.TARGETS])):\n",
    "    train_df.loc[valid_index, 'fold'] = int(n)\n",
    "train_df['fold'] = train_df['fold'].astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f1d229-abd5-43f7-a013-3aadb6bf3d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)\n",
    "TOKENIZER.save_pretrained(CFG.OUTPUT+'tokenizer/')\n",
    "CFG.TOKENIZER = TOKENIZER\n",
    "del TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce162c40-387b-461d-aeba-6f94dcd14b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eadead932f407cbfb4e5bc9c59feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 1428\n",
      "after: 1428\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "lengths = []\n",
    "tk0 = tqdm(train_df['full_text'].fillna(\"\").values, total=len(train_df))\n",
    "for text in tk0:\n",
    "    length = len(CFG.TOKENIZER(text, add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "new_max_l = max(lengths) + 2 # cls & sep\n",
    "\n",
    "print('before:', CFG.MAX_LEN)\n",
    "CFG.MAX_LEN = new_max_l\n",
    "print('after:', CFG.MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ce0227-e1df-4bb0-972e-cb0fdfb8e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FB3Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df['full_text'].values\n",
    "        self.labels = df[CFG.TARGETS].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = CFG.TOKENIZER.encode_plus(\n",
    "            self.texts[item], \n",
    "            return_tensors=None, \n",
    "            add_special_tokens=True, \n",
    "            max_length=CFG.MAX_LEN,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype=torch.long) \n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        return inputs, label\n",
    "    \n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8551082c-a1f7-44be-af30-66ae3c17b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(CFG.MODEL_NAME, output_hidden_states=True)\n",
    "        self.config.hidden_dropout = 0.\n",
    "        self.config.hidden_dropout_prob = 0.\n",
    "        self.config.attention_dropout = 0.\n",
    "        self.config.attention_probs_dropout_prob = 0.\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(CFG.MODEL_NAME, config=self.config)\n",
    "\n",
    "        if CFG.GRAD_CHECKPOINT:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        \n",
    "        self.layer_pool = None\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        all_hidden_states = torch.stack(outputs[1])\n",
    "        weighted_pooling_embeddings = self.layer_pool(all_hidden_states)\n",
    "        feature = self.pool(weighted_pooling_embeddings, inputs['attention_mask'])\n",
    "\n",
    "        \n",
    "        output = self.fc(feature)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d7bf35-f97a-4b48-bc59-2dcab6d59a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        adv_param=\"weight\",\n",
    "        adv_lr=1,\n",
    "        adv_eps=0.2,\n",
    "        start_epoch=0,\n",
    "        adv_step=1,\n",
    "        scaler=None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.adv_param = adv_param\n",
    "        self.adv_lr = adv_lr\n",
    "        self.adv_eps = adv_eps\n",
    "        self.start_epoch = start_epoch\n",
    "        self.adv_step = adv_step\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def attack_backward(self, inputs, labels, epoch):\n",
    "        if (self.adv_lr == 0) or (epoch < self.start_epoch):\n",
    "            return None\n",
    "\n",
    "        self._save() \n",
    "        for i in range(self.adv_step):\n",
    "            self._attack_step() \n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_preds = self.model(inputs)\n",
    "                adv_loss = self.criterion(y_preds, labels)\n",
    "                \n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(adv_loss).backward()\n",
    "            \n",
    "        self._restore()\n",
    "\n",
    "    def _attack_step(self):\n",
    "        e = 1e-6\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
    "                    )\n",
    "                # param.data.clamp_(*self.backup_eps[name])\n",
    "\n",
    "    def _save(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps,\n",
    "                    )\n",
    "\n",
    "    def _restore(self,):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fcc4ad-9cbb-43ea-8084-1033a116d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143764\n",
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=1., emb_name='word_embeddings'):\n",
    "        \"\"\"\n",
    "        敵対的な摂動を求め、現在のembedding layerに摂動を加える\n",
    "        \"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "                    \n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        \"\"\"\n",
    "        敵対的な摂動を求める際に変更してしまったembedding layerのパラメータについて\n",
    "        元のパラメータを代入する\n",
    "        \"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "            self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca222f10-6a3c-4b5a-8724-156a68715edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afca21d3-dc6f-4456-bc18-d1c968a2b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "         'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff45896-4223-4c49-9b67-82ab39e5f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "class PriorWD(Optimizer):\n",
    "    def __init__(self, optim, use_prior_wd=False, exclude_last_group=True):\n",
    "        super(PriorWD, self).__init__(optim.param_groups, optim.defaults)\n",
    "        self.param_groups = optim.param_groups\n",
    "        self.optim = optim\n",
    "        self.use_prior_wd = use_prior_wd\n",
    "        self.exclude_last_group = exclude_last_group\n",
    "        self.weight_decay_by_group = []\n",
    "        for i, group in enumerate(self.param_groups):\n",
    "            self.weight_decay_by_group.append(group[\"weight_decay\"])\n",
    "            group[\"weight_decay\"] = 0\n",
    "\n",
    "        self.prior_params = {}\n",
    "        for i, group in enumerate(self.param_groups):\n",
    "            for p in group[\"params\"]:\n",
    "                self.prior_params[id(p)] = p.detach().clone()\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        if self.use_prior_wd:\n",
    "            for i, group in enumerate(self.param_groups):\n",
    "                for p in group[\"params\"]:\n",
    "                    if self.exclude_last_group and i == len(self.param_groups):\n",
    "                        p.data.add_(-group[\"lr\"] * self.weight_decay_by_group[i], p.data)\n",
    "                    else:\n",
    "                        p.data.add_(\n",
    "                            -group[\"lr\"] * self.weight_decay_by_group[i], p.data - self.prior_params[id(p)],\n",
    "                        )\n",
    "        loss = self.optim.step(closure)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_distance_to_prior(self, param):\n",
    "        assert id(param) in self.prior_params, \"parameter not in PriorWD optimizer\"\n",
    "        return (param.data - self.prior_params[id(param)]).pow(2).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4ad0d4-f4d0-4590-b3b1-bcf394d04435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(epoch, train_loader, model, awp, fgm, criterion, optimizer, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=is_gpu):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            \n",
    "        if CFG.ACCUMLATION > 1:\n",
    "            loss = loss / CFG.ACCUMLATION\n",
    "            \n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        awp.attack_backward(inputs, labels, epoch) \n",
    "        \n",
    "        # FGM\n",
    "        if epoch < CFG.FGM_END:\n",
    "            fgm.attack(epsilon=CFG.FGM_EPS, emb_name='word_embeddings')\n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_preds = model(inputs)\n",
    "                loss_adv = criterion(y_preds, labels)\n",
    "            #optimizer.zero_grad()\n",
    "            scaler.scale(loss_adv).backward()\n",
    "            fgm.restore()          \n",
    "        \n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.GRAD_NORM)\n",
    "        \n",
    "        if (step + 1) % CFG.ACCUMLATION == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            scheduler.step()\n",
    "                \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            \n",
    "        if CFG.ACCUMLATION > 1:\n",
    "            loss = loss / CFG.ACCUMLATION\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e3042a-81ec-4d4f-a1f9-be2731dd6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(y_pred, y_true):\n",
    "    mask = nn.L1Loss(reduction='none')(y_pred, y_true) < 1.5\n",
    "    loss = nn.MSELoss(reduction='none')(y_pred, y_true)\n",
    "    loss = torch.mean(loss * mask.float())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8945c2bc-2a50-469b-a6b6-36b0d731c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(fold, seed, r):\n",
    "    _train_df = train_df.copy()\n",
    "    if r == 'up':\n",
    "        _train_df[CFG.TARGETS] = _train_df[CFG.TARGETS].applymap(math.ceil).astype(float)  # UP\n",
    "    elif r == 'cut':\n",
    "        _train_df[CFG.TARGETS] = _train_df[CFG.TARGETS].applymap(math.floor).astype(float)  # CUT\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "    valid_df = _train_df.query(f\"fold=={fold}\")\n",
    "    valid_labels = valid_df[CFG.TARGETS].values\n",
    "    train_dataset = FB3Dataset(_train_df.query(f\"fold!={fold}\"))\n",
    "    valid_dataset = FB3Dataset(valid_df)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.BS,\n",
    "                              shuffle=True,\n",
    "                              #collate_fn=DataCollatorWithPadding(tokenizer=CFG.TOKENIZER, padding='longest'),\n",
    "                              num_workers=CFG.N_WORKER, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.BS,\n",
    "                              shuffle=False,\n",
    "                              #collate_fn=DataCollatorWithPadding(tokenizer=CFG.TOKENIZER, padding='longest'),\n",
    "                              num_workers=CFG.N_WORKER, pin_memory=True, drop_last=False)\n",
    "\n",
    "    model = CustomModel()\n",
    "    torch.save(model.config, CFG.OUTPUT + 'config.pth')\n",
    "\n",
    "    # load pre-train model\n",
    "    path = f\"pseudo_base/microsoft-deberta-v3-base_seed2_fold{fold}_best.pth\"   \n",
    "    state = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    \n",
    "    \n",
    "    # WeightedLayerPooling\n",
    "    layer_start = 12\n",
    "    model.layer_pool = WeightedLayerPooling(\n",
    "        model.config.num_hidden_layers, \n",
    "        layer_start=layer_start, layer_weights=None\n",
    "    )\n",
    "        \n",
    "    model.to(device)\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.ENCODER_LR, \n",
    "                                                decoder_lr=CFG.DECODER_LR,\n",
    "                                                weight_decay=CFG.WEIGHT_DECAY)\n",
    "\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.ENCODER_LR, eps=CFG.EPS, betas=CFG.BETAS, correct_bias=True)\n",
    "    optimizer = PriorWD(optimizer, use_prior_wd=True)\n",
    "    \n",
    "    num_train_steps = int(len(train_dataset) / CFG.BS * CFG.N_EPOCH)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=CFG.N_WARMUP, num_training_steps=num_train_steps, num_cycles=CFG.N_CYCLES\n",
    "    )\n",
    "\n",
    "    criterion = nn.SmoothL1Loss(reduction='mean', beta=1.0)\n",
    "    #criterion = svm_loss\n",
    "    \n",
    "    awp = AWP(model,\n",
    "              optimizer,\n",
    "              criterion,\n",
    "              adv_lr=CFG.ADV_LR,\n",
    "              adv_eps=CFG.ADV_EPS,\n",
    "              start_epoch=CFG.ADV_START,\n",
    "              scaler=scaler\n",
    "    )\n",
    "    fgm = FGM(model)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_predictions = None\n",
    "    for epoch in range(CFG.N_EPOCH):\n",
    "        avg_loss = train_fn(epoch, train_loader, model, awp, fgm, criterion, optimizer, scheduler)\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion)\n",
    "\n",
    "        score, _ = get_score(valid_labels, predictions)\n",
    "        if best_score > score:\n",
    "            best_score = score\n",
    "            best_predictions = predictions\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                         f\"{CFG.OUTPUT}/{CFG.MODEL_NAME.replace('/', '-')}_seed{seed}_fold{fold}_{r}_best.pth\")\n",
    "        print(f\"[Fold-{fold}] epoch-{epoch}: score={score}\")\n",
    "        \n",
    "        pd.DataFrame([score], columns=[\"score\"]).to_csv(f\"{CFG.OUTPUT}/fold{fold}_epoch{epoch}_{r}.csv\", index=None)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd069237-e7f4-4726-9ced-dd2fb370d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed):\n",
    "    scores = []\n",
    "    for fold in range(CFG.N_FOLD):\n",
    "        if fold in CFG.SKIP_FOLDS:\n",
    "            continue\n",
    "        for r in CFG.ROUND:\n",
    "            print(f\"### Round: {r} ###\")\n",
    "            seed_everything(seed)\n",
    "            score = train_loop(fold, seed, r)\n",
    "            scores.append(score)\n",
    "            print(scores)\n",
    "\n",
    "        state = torch.load(f\"{CFG.OUTPUT}/{CFG.MODEL_NAME.replace('/', '-')}_seed{seed}_fold{fold}_cut_best.pth\", map_location=torch.device('cpu'))\n",
    "        pred1 = state[\"predictions\"]\n",
    "        state = torch.load(f\"{CFG.OUTPUT}/{CFG.MODEL_NAME.replace('/', '-')}_seed{seed}_fold{fold}_up_best.pth\", map_location=torch.device('cpu'))\n",
    "        pred2 = state[\"predictions\"]\n",
    "        pred_avg = np.mean([pred1, pred2], axis=0)\n",
    "\n",
    "        s, _ = get_score(train_df.query(f\"fold=={fold}\")[CFG.TARGETS].values, pred_avg)\n",
    "        print(f\"Fold-{fold} AVG: {s}\")\n",
    "        pd.DataFrame([s], columns=[\"score\"]).to_csv(f\"{CFG.OUTPUT}/fold{fold}_avg.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395ef90-22f1-4253-9dcb-dd2a9d968e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Round: up ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad406acb2e84a02ad3e60c0f87663af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-0: score=0.5359167404985254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f23bd5a942248ba9ee961f82a1473a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-1: score=0.5269224807118801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87eccf1006a3455fac61b8edaeac28a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-2: score=0.5226371040811341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c20b64f64204f88a8adbc6e95bc343e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-3: score=0.5225041905884616\n",
      "[0.5225041905884616]\n",
      "### Round: cut ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad324b97b36a44aca25e3527d5d9c65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-0: score=0.5126534439568952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69296c2e863842f6b3e606c4d67050ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-1: score=0.5092712566004854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79c9c1c65404ef0aad8a6786da4ec33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-2: score=0.5084539432681151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1174bd43fd134cfe9db77f29b5a9433f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-0] epoch-3: score=0.5082278805334223\n",
      "[0.5225041905884616, 0.5082278805334223]\n",
      "Fold-0 AVG: 0.45095617764967355\n",
      "### Round: up ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910b41c3ae9848579891fb2c7b2584c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-0: score=0.5297379794113927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45900b22513c48e8a90a9aad2cf70b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-1: score=0.5270058804866308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269a83dcd7254bdb8b845f9ee7926ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-2: score=0.5179916762047461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d042a8836e04b6d9fe03f853f7d8b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-3: score=0.5171336579678271\n",
      "[0.5225041905884616, 0.5082278805334223, 0.5171336579678271]\n",
      "### Round: cut ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88edb43d8a7949ea9717c6e6883d8c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-0: score=0.5267561228272047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181042f1e0814f399ef92ab8b9abd7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-1: score=0.5221004988209216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5faa438c1c2e43f4a5bd747f93cae152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-2: score=0.5176831874618535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd2ccff8d4f4255bb5d5411e60ed642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-1] epoch-3: score=0.517024299787341\n",
      "[0.5225041905884616, 0.5082278805334223, 0.5171336579678271, 0.517024299787341]\n",
      "Fold-1 AVG: 0.45285120484928004\n",
      "### Round: up ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ef1fc67f6047c9b389389335f9d958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-0: score=0.5273527338041442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f60c60145d4cddadfc772b90dd3694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-1: score=0.5181587572327451\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d86705b993489c8d2eb48586f3cbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-2: score=0.5144660619883723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61d47d74171408cb3dedc8014598bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-3: score=0.5143489718155374\n",
      "[0.5225041905884616, 0.5082278805334223, 0.5171336579678271, 0.517024299787341, 0.5143489718155374]\n",
      "### Round: cut ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04809b757e0545ee82675d8d6f38ee9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-0: score=0.5215667094235169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1a9fd7ea5f401e99c442e852fd04f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-1: score=0.514970206363678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d11c2a317d7447a944c9a947788d43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold-2] epoch-2: score=0.5137952343559582\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(CFG.LOCAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5223d955-def9-40cd-be2d-aa91aa0c3a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /home/jupyter/exp186/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "!kaggle datasets init -p {CFG.OUTPUT}\n",
    "\n",
    "with open(f\"{CFG.OUTPUT}/dataset-metadata.json\", \"r\") as f:\n",
    "    d = json.load(f)\n",
    "    \n",
    "t = f\"FB3 {CFG.EXP} output\"\n",
    "d['title'] = t\n",
    "d['id'] = \"takamichitoda/\"+\"-\".join(t.split())\n",
    "\n",
    "with open(f\"{CFG.OUTPUT}/dataset-metadata.json\", \"w\") as f:\n",
    "    json.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05b17b0-0218-410c-bf47-bf9e0d21abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold2_up_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:21<00:00, 34.7MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold2_up_best.pth (701MB)\n",
      "Starting upload for file fold3_epoch3_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 6.80B/s]\n",
      "Upload successful: fold3_epoch3_cut.csv (25B)\n",
      "Starting upload for file config.pth\n",
      "100%|████████████████████████████████████████| 2.55k/2.55k [00:03<00:00, 701B/s]\n",
      "Upload successful: config.pth (3KB)\n",
      "Starting upload for file fold3_epoch0_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.37B/s]\n",
      "Upload successful: fold3_epoch0_up.csv (25B)\n",
      "Starting upload for file fold0_epoch2_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 11.5B/s]\n",
      "Upload successful: fold0_epoch2_up.csv (25B)\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold3_cut_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:21<00:00, 34.1MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold3_cut_best.pth (701MB)\n",
      "Starting upload for file fold0_epoch1_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.05B/s]\n",
      "Upload successful: fold0_epoch1_cut.csv (25B)\n",
      "Starting upload for file fold0_epoch0_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:05<00:00, 4.83B/s]\n",
      "Upload successful: fold0_epoch0_cut.csv (25B)\n",
      "Starting upload for file fold1_epoch1_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 7.17B/s]\n",
      "Upload successful: fold1_epoch1_up.csv (25B)\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold0_cut_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:22<00:00, 32.6MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold0_cut_best.pth (701MB)\n",
      "Starting upload for file fold1_avg.csv\n",
      "100%|█████████████████████████████████████████| 26.0/26.0 [00:02<00:00, 10.8B/s]\n",
      "Upload successful: fold1_avg.csv (26B)\n",
      "Starting upload for file fold1_epoch2_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 12.4B/s]\n",
      "Upload successful: fold1_epoch2_cut.csv (25B)\n",
      "Starting upload for file fold1_epoch3_cut.csv\n",
      "100%|█████████████████████████████████████████| 24.0/24.0 [00:02<00:00, 12.0B/s]\n",
      "Upload successful: fold1_epoch3_cut.csv (24B)\n",
      "Starting upload for file fold2_epoch2_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:04<00:00, 6.09B/s]\n",
      "Upload successful: fold2_epoch2_up.csv (25B)\n",
      "Starting upload for file fold1_epoch3_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 10.6B/s]\n",
      "Upload successful: fold1_epoch3_up.csv (25B)\n",
      "Starting upload for file fold1_epoch2_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.65B/s]\n",
      "Upload successful: fold1_epoch2_up.csv (25B)\n",
      "Starting upload for file fold2_epoch1_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 8.80B/s]\n",
      "Upload successful: fold2_epoch1_up.csv (25B)\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold3_up_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:20<00:00, 35.4MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold3_up_best.pth (701MB)\n",
      "Skipping folder: tokenizer; use '--dir-mode' to upload folders\n",
      "Starting upload for file fold0_epoch2_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 7.16B/s]\n",
      "Upload successful: fold0_epoch2_cut.csv (25B)\n",
      "Starting upload for file fold3_avg.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 11.3B/s]\n",
      "Upload successful: fold3_avg.csv (25B)\n",
      "Starting upload for file fold3_epoch3_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 10.9B/s]\n",
      "Upload successful: fold3_epoch3_up.csv (25B)\n",
      "Starting upload for file fold0_avg.csv\n",
      "100%|█████████████████████████████████████████| 26.0/26.0 [00:03<00:00, 8.24B/s]\n",
      "Upload successful: fold0_avg.csv (26B)\n",
      "Starting upload for file fold1_epoch0_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 7.68B/s]\n",
      "Upload successful: fold1_epoch0_cut.csv (25B)\n",
      "Starting upload for file fold2_epoch3_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.96B/s]\n",
      "Upload successful: fold2_epoch3_cut.csv (25B)\n",
      "Starting upload for file fold2_epoch0_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 6.51B/s]\n",
      "Upload successful: fold2_epoch0_up.csv (25B)\n",
      "Starting upload for file fold2_avg.csv\n",
      "100%|█████████████████████████████████████████| 26.0/26.0 [00:03<00:00, 7.32B/s]\n",
      "Upload successful: fold2_avg.csv (26B)\n",
      "Starting upload for file fold0_epoch3_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 6.49B/s]\n",
      "Upload successful: fold0_epoch3_cut.csv (25B)\n",
      "Starting upload for file fold0_epoch1_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 11.7B/s]\n",
      "Upload successful: fold0_epoch1_up.csv (25B)\n",
      "Starting upload for file fold0_epoch0_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:04<00:00, 6.05B/s]\n",
      "Upload successful: fold0_epoch0_up.csv (25B)\n",
      "Starting upload for file fold2_epoch2_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.79B/s]\n",
      "Upload successful: fold2_epoch2_cut.csv (25B)\n",
      "Starting upload for file fold1_epoch1_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.53B/s]\n",
      "Upload successful: fold1_epoch1_cut.csv (25B)\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold2_cut_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:21<00:00, 33.7MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold2_cut_best.pth (701MB)\n",
      "Starting upload for file fold3_epoch1_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 9.30B/s]\n",
      "Upload successful: fold3_epoch1_cut.csv (25B)\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold1_up_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:19<00:00, 37.2MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold1_up_best.pth (701MB)\n",
      "Starting upload for file fold3_epoch2_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 6.65B/s]\n",
      "Upload successful: fold3_epoch2_cut.csv (25B)\n",
      "Starting upload for file fold2_epoch3_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 11.7B/s]\n",
      "Upload successful: fold2_epoch3_up.csv (25B)\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold0_up_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:20<00:00, 36.7MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold0_up_best.pth (701MB)\n",
      "Starting upload for file fold1_epoch0_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 10.7B/s]\n",
      "Upload successful: fold1_epoch0_up.csv (25B)\n",
      "Starting upload for file fold2_epoch0_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:02<00:00, 8.86B/s]\n",
      "Upload successful: fold2_epoch0_cut.csv (25B)\n",
      "Starting upload for file fold3_epoch1_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 7.24B/s]\n",
      "Upload successful: fold3_epoch1_up.csv (25B)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file microsoft-deberta-v3-base_seed0_fold1_cut_best.pth\n",
      "100%|████████████████████████████████████████| 701M/701M [00:20<00:00, 36.8MB/s]\n",
      "Upload successful: microsoft-deberta-v3-base_seed0_fold1_cut_best.pth (701MB)\n",
      "Starting upload for file fold2_epoch1_cut.csv\n",
      "100%|█████████████████████████████████████████| 24.0/24.0 [00:02<00:00, 11.0B/s]\n",
      "Upload successful: fold2_epoch1_cut.csv (24B)\n",
      "Starting upload for file fold3_epoch0_cut.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 6.73B/s]\n",
      "Upload successful: fold3_epoch0_cut.csv (25B)\n",
      "Starting upload for file fold0_epoch3_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 6.75B/s]\n",
      "Upload successful: fold0_epoch3_up.csv (25B)\n",
      "Starting upload for file fold3_epoch2_up.csv\n",
      "100%|█████████████████████████████████████████| 25.0/25.0 [00:03<00:00, 7.58B/s]\n",
      "Upload successful: fold3_epoch2_up.csv (25B)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/takamichitoda/FB3-exp186-output\n",
      "ref                                                title                                 size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-------------------------------------------------  -----------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "takamichitoda/fb3-embed-features-for-svr           FB3 embed features for SVR           155MB  2022-11-11 01:26:53              0          0  0.0              \n",
      "takamichitoda/fb3-exp184-output                    FB3 exp184 output                      2GB  2022-11-10 09:13:35              0          0  0.3529412        \n",
      "takamichitoda/fb3-exp180-output                    FB3 exp180 output                      2GB  2022-11-10 00:30:39              0          0  0.3529412        \n",
      "takamichitoda/fb3-round-model                      FB3 round model                        5GB  2022-11-09 09:51:43              0          0  0.25             \n",
      "takamichitoda/fb3-exp179-output                    FB3 exp179 output                      2GB  2022-11-09 07:45:49              0          0  0.3529412        \n",
      "takamichitoda/fb3-distribution-layer-2             FB3 distribution layer 2             921MB  2022-11-09 03:38:57              0          0  0.375            \n",
      "takamichitoda/fb3-exp166-output                    FB3 exp166 output                      2GB  2022-11-07 06:18:38              0          0  0.3529412        \n",
      "takamichitoda/fb3-distribution-pos-and-mask        FB3 distribution pos and mask        962MB  2022-11-07 03:25:00              0          0  0.375            \n",
      "takamichitoda/fb3-distribution-pos                 FB3 distribution pos                 962MB  2022-11-04 11:36:57              0          0  0.375            \n",
      "takamichitoda/fb3-deberta-v3-mask-loss             FB3 DeBERTa v3 mask loss               2GB  2022-11-01 12:21:30              0          0  0.25             \n",
      "takamichitoda/fb3-distribution-mask                FB3 distribution mask                958MB  2022-11-01 07:08:51              0          0  0.375            \n",
      "takamichitoda/fb3-distribution                     FB3 distribution                       2GB  2022-10-30 23:42:33              0          0  0.3529412        \n",
      "takamichitoda/fb3-distribution-exp3                FB3 distribution exp3                  1GB  2022-10-27 10:53:13              0          0  0.3529412        \n",
      "takamichitoda/fb3-distribution-exp2                FB3 distribution exp2                  1GB  2022-10-27 09:50:51              0          0  0.3529412        \n",
      "takamichitoda/fb3-distribution-exp1                FB3 distribution exp1                  1GB  2022-10-27 04:49:43              0          0  0.3529412        \n",
      "takamichitoda/fb3-deberta-v3-weightedlayerpooling  FB3 DeBERTa v3 WeightedLayerPooling    2GB  2022-10-27 02:00:53              0          0  0.25             \n",
      "takamichitoda/fb3-deberta-v3-xsmall-4-layer        FB3 DeBERTa v3 xsmall 4 layer          2GB  2022-10-25 01:28:45              0          0  0.25             \n",
      "takamichitoda/fb3-deberta-v3-4th-tune              FB3 DeBERTa v3 4th tune                1GB  2022-10-24 22:13:21              0          0  0.25             \n",
      "takamichitoda/fb3-exp119-output                    FB3 exp119 output                      2GB  2022-10-19 23:15:40              0          0  0.3529412        \n",
      "takamichitoda/fb3-deberta-v3-3rd-beta-15           FB3 DeBERTa v3 3rd beta 1.5          579MB  2022-10-19 11:45:34              0          0  0.25             \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -p {CFG.OUTPUT}\n",
    "#!kaggle datasets version -m \"test\" -p {CFG.OUTPUT}/\n",
    "\n",
    "!kaggle datasets list -m --sort-by \"updated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc99225-e670-483d-891a-e309ba2e909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'FB3 WLP Round.ipynb'\n",
      "'FB3 WLP mask loss.ipynb'\n",
      "'FB3 training WeightedLayerPooling.ipynb'\n",
      "'FB3 training multi GPU.ipynb'\n",
      " exp119\n",
      " exp15x\n",
      " exp166\n",
      " exp179\n",
      " exp180\n",
      " exp184\n",
      " exp186\n",
      " fb3-make-pseudo-label-4th\n",
      " fb3-pseudo-train-3rd.log\n",
      " feedback-prize-english-language-learning\n",
      " kaggle.json\n",
      " output\n",
      " pseudo\n",
      " pseudo_base\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59011cb7-e41a-4702-bbc3-4b8ae9e59847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
