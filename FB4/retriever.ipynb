{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae7ed1b-e4ea-4a5e-aa32-9f5a9f36b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  8 01:47:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   51C    P0    28W /  70W |      0MiB / 15360MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae3f2b0-5f65-469d-a51f-ad0197829eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API 1.5.12\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p .kaggle\n",
    "!cp \"./kaggle.json\" .kaggle/\n",
    "!chmod 600 .kaggle/kaggle.json\n",
    "!cp -r .kaggle /root\n",
    "\n",
    "!kaggle -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81175d06-e36c-42db-9cd2-f154221a709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.20.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence_transformers) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence_transformers) (9.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=39a6c7a64bb3aacb5ba9f0104ce1ec63556deb14d1d7730d2a5d0c536983a513\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-2.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3837ef4c-10c9-4b57-a4c4-fcb5214ae2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading learning-equality-curriculum-recommendations.zip to /home/jupyter\n",
      " 95%|██████████████████████████████████████▉  | 241M/254M [00:02<00:00, 121MB/s]\n",
      "100%|█████████████████████████████████████████| 254M/254M [00:02<00:00, 126MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c learning-equality-curriculum-recommendations\n",
    "!mkdir -p input_data/learning-equality-curriculum-recommendations\n",
    "!unzip learning-equality-curriculum-recommendations.zip -d input_data/learning-equality-curriculum-recommendations\n",
    "!rm learning-equality-curriculum-recommendations.zip\n",
    "\n",
    "!dname=\"lecr-1st-train-data\" && \\\n",
    " kaggle datasets download -d takamichitoda/\"$dname\" && \\\n",
    " mkdir -p input_data/\"$dname\"  && \\\n",
    " unzip \"$dname\".zip -d input_data/\"$dname\"  && \\\n",
    " rm \"$dname\".zip\n",
    "\n",
    "!dname=\"lecr-cut-train-dataset\" && \\\n",
    " kaggle datasets download -d takamichitoda/\"$dname\" && \\\n",
    " mkdir -p input_data/\"$dname\"  && \\\n",
    " unzip \"$dname\".zip -d input_data/\"$dname\"  && \\\n",
    " rm \"$dname\".zip\n",
    "\n",
    "!kaggle datasets download -d takamichitoda/lecr-topic-with-parent\n",
    "!mkdir -p input_data/lecr-topic-with-parent\n",
    "!unzip lecr-topic-with-parent.zip -d input_data/lecr-topic-with-parent\n",
    "!rm lecr-topic-with-parent.zip\n",
    "\n",
    "!dname=\"lecr-cv-data\" && \\\n",
    " kaggle datasets download -d takamichitoda/\"$dname\" && \\\n",
    " mkdir -p input_data/\"$dname\"  && \\\n",
    " unzip \"$dname\".zip -d input_data/\"$dname\"  && \\\n",
    " rm \"$dname\".zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030c1b21-08a0-435a-8b5a-73f84724e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, InputExample\n",
    "from sentence_transformers import evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419e9f8f-0f8f-4388-a681-e546b69a0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    INPUT = './input_data/learning-equality-curriculum-recommendations'\n",
    "\n",
    "    TRAIN_1ST = './input_data/lecr-1st-train-data/first_stage_train.json'\n",
    "    CUT_TEXT = './input_data/lecr-cut-train-dataset'\n",
    "    CV_SPLIT = './input_data/lecr-cv-data'\n",
    "    TOPIC_WITH_PARENT = './input_data/lecr-topic-with-parent/topics_has_content_with_parent_title.csv'\n",
    "\n",
    "    #MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "    MODEL_NAME = 'xlm-roberta-base'\n",
    "    #MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    OUTPUT = './output/xlm-roberta'\n",
    "    BS = 128 #256\n",
    "    N_EPOCH = 50\n",
    "    WARMUP_RATE = 0.0\n",
    "    LR = 5e-05\n",
    "    MARGIN = 0.5\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "    \n",
    "    SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1741ac85-adbc-43d1-a511-28f9a05b05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc24ccf-e336-4b86-854c-44661f7b663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = pd.read_csv(f'{CFG.INPUT}/content.csv')\n",
    "content_df = content_df.fillna('')\n",
    "\n",
    "topics_df = pd.read_csv(f'{CFG.TOPIC_WITH_PARENT}')\n",
    "correlations_df = pd.read_csv(f'{CFG.CV_SPLIT}/correlations_with_fold.csv')\n",
    "correlations_with_topics_df = correlations_df.merge(topics_df, left_on='topic_id', right_on='id').drop(columns='id')\n",
    "valid_correlations_with_topics_df = correlations_with_topics_df.query('fold==0').fillna('')\n",
    "train_correlations_with_topics_df = correlations_with_topics_df.query('fold!=0').fillna('')\n",
    "\n",
    "with open(f'{CFG.TRAIN_1ST}', 'r') as f:\n",
    "    first_stage_train = json.load(f)\n",
    "    \n",
    "with open(f'{CFG.CUT_TEXT}/content_joint_sentences.json', 'r') as f:\n",
    "    content_joint_sentences = json.load(f)\n",
    "with open(f'{CFG.CUT_TEXT}/topic_joint_sentence.json', 'r') as f:\n",
    "    topic_joint_sentence = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8148a39-6a72-48f0-8f88-5b56ea7b469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sentence_transformers.util import dot_score\n",
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53d81a8-e6c3-47eb-ae36-1388179cd01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#model = SentenceTransformer(CFG.MODEL_NAME)\n",
    "\n",
    "word_embedding_model = models.Transformer(CFG.MODEL_NAME)\n",
    "\n",
    "tokens = [\"<my_sep>\"]\n",
    "word_embedding_model.tokenizer.add_tokens(tokens, special_tokens=True)\n",
    "word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n",
    "\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "#train_loss = losses.ContrastiveLoss(\n",
    "#    model=model,\n",
    "#    margin=CFG.MARGIN,\n",
    "    #distance_metric=losses.SiameseDistanceMetric.EUCLIDEAN,\n",
    "#)\n",
    "#train_loss = losses.OnlineContrastiveLoss(model=model)\n",
    "#train_loss = losses.MultipleNegativesRankingLoss(model=model, scale=1.0, similarity_fct=dot_score)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d11fd6d-b9c9-42e7-91ae-ab846fec9ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20164acadb46437392ff22550bde8234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2668159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = []\n",
    "for ids in tqdm(first_stage_train):\n",
    "    topic_text = topic_joint_sentence[ids['topic_id']]\n",
    "    content_text = content_joint_sentences[ids['content_id']]\n",
    "    label = ids['label']\n",
    "    #e = InputExample(texts=[topic_text, content_text], label=label)\n",
    "    if label == 0:\n",
    "        continue\n",
    "    e = InputExample(texts=[topic_text, content_text])\n",
    "    examples.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3978a7-dbdc-4878-83f1-aa5daecf8ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b56a03313247efb9919a33df343fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442baa5185784133a8dc17f7658166d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba06512fa1542c28148942d2383cec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevant_docs = {}\n",
    "for _, row in tqdm(valid_correlations_with_topics_df.iterrows(), total=len(valid_correlations_with_topics_df)):\n",
    "    relevant_docs[row['topic_id']] = set(row['content_ids'].split())\n",
    "    \n",
    "queries = {}\n",
    "for _, row in tqdm(valid_correlations_with_topics_df.iterrows(), total=len(valid_correlations_with_topics_df)):\n",
    "    queries[row['topic_id']] = topic_joint_sentence[row['topic_id']]\n",
    "    \n",
    "corpus = {}\n",
    "for _, row in tqdm(content_df.iterrows(), total=len(content_df)):\n",
    "    corpus[row['id']] = content_joint_sentences[row['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa121a9-1849-48d2-b427-16216fd7cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    queries,\n",
    "    corpus,\n",
    "    relevant_docs,\n",
    "    precision_recall_at_k=[50, 100],\n",
    "    name='ir',\n",
    "    write_csv=True,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334160f-49dc-476a-83b8-367db6f48b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org n_step: 1884\n",
      "update n_step: 1884\n",
      "warmup_steps: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef75e7ca7ec40dc8b8483fc007f96e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cfd1ccd2b2461a9faa0fbdbe88be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6b2493a86d4e77875abc155dfbfd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus Chunks:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Corpus Chunks:  25% 1/4 [02:26<07:18, 146.23s/it]\u001b[A\n",
      "Corpus Chunks:  50% 2/4 [04:53<04:53, 146.97s/it]\u001b[A\n",
      "Corpus Chunks:  75% 3/4 [07:19<02:26, 146.41s/it]\u001b[A\n",
      "Corpus Chunks: 100% 4/4 [07:32<00:00, 113.19s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cad616b3ec349318865c1bb4e4d7ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dbf0d65bf8456caca0f8fbe799527a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus Chunks:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Corpus Chunks:  25% 1/4 [02:27<07:21, 147.12s/it]\u001b[A\n",
      "Corpus Chunks:  50% 2/4 [04:54<04:54, 147.09s/it]\u001b[A\n",
      "Corpus Chunks:  75% 3/4 [07:22<02:27, 147.70s/it]\u001b[A\n",
      "Corpus Chunks: 100% 4/4 [07:36<00:00, 114.11s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbabfcd53ebe438db67f3cded1695ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27eb6aa4b6d4db6aeda79ede3bbed2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus Chunks:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Corpus Chunks:  25% 1/4 [02:28<07:26, 148.88s/it]\u001b[A\n",
      "Corpus Chunks:  50% 2/4 [04:55<04:55, 147.76s/it]\u001b[A\n",
      "Corpus Chunks:  75% 3/4 [07:22<02:27, 147.32s/it]\u001b[A\n",
      "Corpus Chunks: 100% 4/4 [07:36<00:00, 114.12s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e800bab08e74ea4b5ac9707ae76b6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14752939036d43e89bdff1f2f155ceab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus Chunks:   0% 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG.SEED)\n",
    "train_dataloader = DataLoader(examples, shuffle=True, batch_size=CFG.BS)\n",
    "\n",
    "n_step = len(train_dataloader)\n",
    "print(\"org n_step:\", n_step)\n",
    "#n_step = 2500\n",
    "print(\"update n_step:\", n_step)\n",
    "\n",
    "warmup_steps = int(len(train_dataloader) * CFG.N_EPOCH * CFG.WARMUP_RATE)\n",
    "print('warmup_steps:', warmup_steps)\n",
    "\n",
    "model.fit([(train_dataloader, train_loss)],\n",
    "          epochs=CFG.N_EPOCH,\n",
    "          evaluator=ir_evaluator,\n",
    "          #evaluation_steps=n_step,\n",
    "          warmup_steps=warmup_steps,\n",
    "          max_grad_norm=CFG.MAX_GRAD_NORM,\n",
    "          optimizer_params={'lr': CFG.LR},\n",
    "          scheduler='warmupcosine',\n",
    "          use_amp=True,\n",
    "          output_path=f'{CFG.OUTPUT}',\n",
    "          #checkpoint_save_steps=n_step,\n",
    "          checkpoint_path=f'{CFG.OUTPUT}/checkpoints/',\n",
    "          show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d471e2f-07dd-4374-b01b-c3a2a93abe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf21ba9-be49-4991-840b-ffcd5aff45d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
